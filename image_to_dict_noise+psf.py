#===========================================================================================
# Transfer the image data to dictionary format for the loading in VQ-VAE code
# noise+psf: add noise map and PSF in the dictionary
#     - noise map is generated by the 'generate_noise_map' function which uses the value
#       at the 4 corners in the images to estimate the mean (mu) and variance (var) of
#       the Gaussian distribution
#     - PSF is from 3D-HST.
# To-do list: (1) Need to update the code to use hef5 file to save a larger dataset
#             (2) Find a better way to calculate the background noise
#             (3) All images use the same PSF at the moment
#===========================================================================================
import os
import numpy as np
import pickle
from astropy.io import fits
from matplotlib import pyplot as plt
from astropy.convolution import Gaussian2DKernel

## Function
def maxmin(data):
    """ Normalised the images data to [0,1] """
    max = np.max(data)
    min = np.min(data)
    if max != min:
        data = ( data - min )/ np.float( max - min )
    else:
        data = data - min
    return data

def generate_noise_map(imgdata):
    """ Generate the noise map """
    sigma_area1 = imgdata[:5, :5]
    sigma_area2 = imgdata[:5, :-5]
    sigma_area3 = imgdata[:-5, :5]
    sigma_area4 = imgdata[:-5, :-5]
    
    sigma1 = np.std(sigma_area1)
    sigma2 = np.std(sigma_area2)
    sigma3 = np.std(sigma_area3)
    sigma4 = np.std(sigma_area4)
    
    row, col = np.shape(imgdata)
    mu = np.mean([sigma1, sigma2, sigma3, sigma4]) # calculate the average of noise background
    var = np.var([sigma1, sigma2, sigma3, sigma4]) # calculate the variance of noise background
    gauss = np.random.normal(mu, var, (row, col))
    noise_map = gauss
    
    return noise_map

def psf_stamp(psf_data, image_size):
    psf_ori_shape = np.shape(psf_data)[0]
    diff = (image_size - psf_ori_shape)// 2
    psf_data_extend = np.zeros((image_size, image_size))
    psf_data_extend[diff:(diff+psf_ori_shape), diff:(diff+psf_ori_shape)] += psf_data
    return psf_data_extend

## directory
PATH_TO_IMAGES = 'data/' # path to images
PATH_output_IMAGES = 'data/' # path to the output of dictionary
PATH_TO_PSF = 'PSF/' # path to psf file
image_paths = os.listdir(PATH_TO_IMAGES)
psf_paths = 'psf_filename' # psf filename

## variables
image_size = 84

list_of_id, list_of_imgfn, list_of_images, list_of_noise, list_of_psf = [], [], [], [], []
for im in image_paths:
    image = fits.open(PATH_TO_IMAGES + im)
    img_data = image[0].data.astype(np.float32)
    img_data = maxmin(img_data)
    psf = fits.open(PATH_TO_PSF + psf_paths)
    psf_data = psf[0].data.astype(np.float32)
    psf_data_stamp = psf_stamp(psf_data, image_size)
    width, height = img_data.shape[0], img_data.shape[1]
    if (width, height) == (image_size, image_size):
        list_of_id.append(im[:-7])
        list_of_imgfn.append(im)
        list_of_images.append(img_data)
        list_of_psf.append(psf_data_stamp) #psf
        # generate noise map
        noise_map = generate_noise_map(img_data)
        list_of_noise.append(noise_map)

list_of_images = np.array(list_of_images)
list_of_noise = np.array(list_of_noise)
list_of_psf = np.array(list_of_psf)
imdict = {'id': list_of_id, 'filename': list_of_imgfn, 'images': list_of_images, 'noise': list_of_noise, 'psf': list_of_psf}

#print(list_of_image_data)
with open(PATH_output_IMAGES + 'data_noise+psf.dict', 'wb') as handle:
    pickle.dump(imdict, handle, protocol=pickle.HIGHEST_PROTOCOL)
